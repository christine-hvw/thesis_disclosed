---
title: "Exploratory Analyses"
author: "Christine Hedde - von Westernhagen"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(tidyverse)
library(muxViz)
library(ggplot2)
library(igraph)
library(Matrix)
library(rgl)      # output 3d plots
library(tidytext) # ordering factors within facets
library(ggsankey) # sankey diagrams
library(patchwork)
```

# Data prep

```{r}
nodes <- read.csv(here("dummy_data/popnet_nodelist.csv"))
edges <- read.csv(here("dummy_data/popnet_edgelist.csv"))
```

```{r}
# types of edges
edges %>% 
  count(edgetype) %>% 
  arrange(desc(n))

# number of nodes
length(unique(c(edges$source, edges$target)))

# missing nodes
nodes[!nodes$node_id %in%  unique(c(edges$source, edges$target)),]
```

**Network sampling**

Example code if sampling is necessary.

```{r, eval = FALSE}
child_edges <- edges[edges$edgetype == "child",]

child_nodes <-  child_edges["source"]

keep_relations <- c("child", "parent", "sibling")

# sampling, e.g., 30% of children
sample_frac <- 0.3
pop_size <- nrow(child_nodes)

set.seed(789)
child_sample_idx <- sample(x = 1:pop_size, size = sample_frac * pop_size, replace = FALSE)

child_sample_ids <- child_nodes[child_sample_idx,]

# subset edge data to sampled children in specified relations
egdes_sample <- edges[(edges$source %in% child_sample_ids | edges$target %in% child_sample_ids) &
                        (edges$edgetype %in% keep_relations),]
```

Here, proceed with full data set.

```{r}
# Make single-layer network
g_all <- graph_from_data_frame(d = edges[, c("source", "target")],
                               vertices = nodes$node_id)
```

```{r}
# Make multi-layer network
groups <- unique(edges$edgetype)
layers <- 4 # (after collapsing family categories)
obs <- nrow(nodes)

node_tensor <- list()
g_list <- list()

for (g in groups) {
  graph <- graph_from_data_frame(d = edges[edges$edgetype == g, c("source", "target")],
                                 # include ALL vertices
                                 vertices = nodes$node_id)
  g_list[[g]] <- graph
  node_tensor[[g]] <- as_adjacency_matrix(graph)
}


# collapse corresponding categories into "family"
family <-  c('aunt / uncle', 'neighbor', 'cousin', 'mother / father-in-law', 'sibling',  'grandchild', 'grandparent',  'niece / nephew', 'parent', 'sister / brother-in-law',  'child', 'daughter / son-in-law', 'partner')

graph_fam <- graph_from_data_frame(d = edges[edges$edgetype %in% family, c("source", "target")],
                                   # include ALL vertices
                                   vertices = nodes$node_id)
g_list[["family"]] <- graph_fam
node_tensor[["family"]] <- as_adjacency_matrix(graph_fam)

# remove subcategories of family from graph
g_list <- g_list[!names(g_list) %in% family]
node_tensor <- node_tensor[!names(node_tensor) %in% family]

# Define layer tensor
layer_tensor <- Matrix(c(0,1,1,1,
                         1,0,1,1,
                         1,1,0,1,
                         1,1,1,0) , nrow = 4, sparse = TRUE)

# Build supra-adjacency matrix
M <- BuildSupraAdjacencyMatrixFromEdgeColoredMatrices(node_tensor, layer_tensor, layers, obs)
```

# Explore multi-layer network

## Heatmap

```{r, fig.height=7, fig.width=7}
#rotate <- function(mat) t(mat[nrow(mat):1, ,drop = FALSE])

#M_flip <- rotate(as.matrix(M))

# image(t(M_flip),
#       axes = FALSE)

heatmap(as.matrix(M), Rowv = NA, Colv = NA, useRaster = TRUE,
        col = hcl.colors(100), revC = TRUE,
        labRow = rep(1:nrow(nodes), layers), labCol = rep(1:nrow(nodes), layers))
```

## 3D plot

```{r}
set.seed(789)
lay <- layoutMultiplex(g_list, layout = "comp", box = TRUE)

plot_multiplex3D(g_list,
  layer.layout = lay, layer.colors = c(2:5),
  layer.shift.x = 0.3, layer.space = 2,
  layer.scale = 2.2, layer.alpha = rep(.2, length(g_list)),
  layer.labels = names(g_list), layer.labels.cex = 1,
  node.size.values = 6,
  FOV = 0
)

snapshot3d("3dplot_dummy.png", fmt = "png", width = 1024, height = 1024)

knitr::include_graphics("3dplot_dummy.png")
```

# Explore multi vs. single-layer centralities

## Compute centralities

```{r}
deg_single <- degree(g_all)
deg_mult <- c(GetMultiDegreeSum(M, layers, obs, isDirected = FALSE))

eig_single <- eigen_centrality(g_all)$vector
eig_mult <- c(GetMultiEigenvectorCentrality(M, layers, obs))

pr_single <- page_rank(g_all)$vector
pr_mult <- c(GetMultiPageRankCentrality(M, layers, obs))

clo_single <- closeness(g_all)
clo_mult <- GetMultiClosenessCentrality(M, layers, obs)[[1]]
```

## Compare node ranking

```{r, fig.width=4, fig.height=5, warning=FALSE}
plot_centrality_ranking <- function(type, single, multi, node_ids, yaxis_title = TRUE) {
  
  df <- data.frame("single" = single, "multi" = multi) %>% 
    mutate(id = as.factor(node_ids)) %>% 
    pivot_longer(cols = -id, names_to = "layers", values_to = type) %>% 
    group_by(layers) %>% 
    mutate(rank = rank(desc(.data[[type]]), ties.method = "min")) %>% 
    ungroup()
  
  top20_dat <- df %>% 
    arrange(layers, rank) %>% 
    group_by(layers) %>% 
    mutate(top20 = ifelse(row_number() %in% c(1:20), as.character(id), NA)) %>% 
    ungroup() %>% 
    mutate(top20 = ifelse(id %in% top20, TRUE, NA)) %>% 
    filter(top20 == TRUE) %>% 
    select(-.data[[type]]) %>% 
    pivot_wider(values_from = c("rank"), names_from = layers)

  sankey_dat <- top20_dat %>% 
    make_long("single", "multi")
  
  ggplot(sankey_dat, aes(x = x, next_x = next_x, node = node, next_node = next_node,
                         fill = node/max(df$rank)*100, label = node)) +
    geom_sankey(flow.alpha = .6, space = 1.5, width = 0.15) +
    geom_sankey_label(size = 2.2, color = "black", fill = "white", space = 1.5, alpha = 0.8) +
    theme_sankey() +
    scale_fill_viridis_c(option = "plasma") +
    scale_x_discrete(labels = c("single" = "Single-layer", "multi" = "Multi-layer")) +
    labs(x = NULL, fill = "Node rank (%)", title = type) +
    list(if(yaxis_title){labs(y =  "Node rank (absolute)")} else {labs(y = NULL)}) +
    coord_cartesian(xlim = c(1.4, 2)) +
    guides(fill = guide_colorbar(title.hjust = 0.5)) +
    theme(legend.position = c(.87, .5),
          plot.title = element_text(hjust = 0.34, margin = margin(b = -10)))
}

# Degree
plt_deg <- plot_centrality_ranking("Degree centrality", deg_single, deg_mult, nodes$node_id)

# Eigenvector
plt_eig <- plot_centrality_ranking("Eigenvector centrality", eig_single, eig_mult, nodes$node_id, yaxis_title = FALSE)

# PageRank
plt_pr <- plot_centrality_ranking("PageRank centrality", pr_single, pr_mult, nodes$node_id)

# Closeness
plt_clo <- plot_centrality_ranking("Closeness centrality", clo_single, clo_mult, nodes$node_id, yaxis_title = FALSE)
```


```{r, fig.width=8, fig.height=10, warning=FALSE}
(plt_deg + plt_eig) /
  (plt_pr + plt_clo)

ggsave(here("analyses/sankeyplot_all.png"), dpi = 600,
       width = 8.2, height = 10)
```


```{r, fig.width=8, fig.height=5, warning=FALSE}
plt_eig <- plot_centrality_ranking("Eigenvector centrality", eig_single, eig_mult, nodes$node_id)
plt_pr <- plot_centrality_ranking("PageRank centrality", pr_single, pr_mult, nodes$node_id, yaxis_title = FALSE)

plt_eig + plt_pr

ggsave(here("analyses/sankeyplot_eig-pr.png"), dpi = 600,
       width = 8.2, height = 5)
```


# Epidemic modeling

**Function for SIR network model**

Similar to [`epimdr::NetworkSIR()`](https://github.com/objornstad/epimdr/blob/master/rcode/chapter12code.r), [Book link](https://link.springer.com/chapter/10.1007/978-3-319-97487-3_12).

```{r}
model_sir_multiplex <- function(adj_mats, tau, gamma, r_stochastic = "individual",
                                seed_infs = 1, random_seed = 789, t_max = Inf) {
  #adj_mats = list of separate adj. mats. per layer (= node tensor)
  #tau  =  vector of probabilities of infection across an edge in each layer
  #gamma  =  recovery time (not layer specific)
  #r_stochastic = is recovery stochastic on the individual level or per simulation?
  #seed_infs = no. of infected seed nodes
  #random_seed = seed for sampling seed nodes (lol)
  #t_max = max. no. of time steps
  
  layers <- length(adj_mats)
  N <- dim(adj_mats[[1]])[1]
  S <- matrix(rep(1, N), nrow = N, ncol = 1) #First susceptibles (all)
  I <- matrix(rep(0, N), nrow = N, ncol = 1) #First infecteds 
  R <- matrix(rep(0, N), nrow = N, ncol = 1) #First removed 
  
  # sample seed infection(s)
  if(!is.null(random_seed)) set.seed(random_seed)
  
  I1 <- sample(1:N, size = seed_infs)
  # change status of seed nodes
  S[I1,1] <- 0
  I[I1,1] <- 1
  
  # if true, set recovery time sampled from Weibull distribution per simulation
  if(r_stochastic == "simulation") {
    rec_time <- ceiling(rweibull(1, scale = gamma, shape = 1))
    } else { 
    rec_time <- "individual"
  }
  
  # storage for new infections per layer
  newI_layers <- vector(mode = "list", length = layers)
  
  # while there are still infecteds (=not recovered) & t is smaller than t_max...
  t <- 1
  while(sum(I[,t]) > 0 & t < t_max) {
    
    t <- t + 1
    
    for(l in 1:layers) {
      # vector of infection status neighbors
      infneigh <- adj_mats[[l]] %*% I[,t-1]
      # prob. of infection along each edge (Reed-Frost model)
      pinf <- as.vector(1 - (1 - tau[l])^infneigh)
    
      # create new infections based on pinf in layer
      newI_layers[[l]] <- rbinom(N, S[,t-1], pinf)
    }
    
    # get union of infections across layers
    # -> if infected in one layer, you're infected in all layers
    newI <- as.integer(apply(do.call("cbind", newI_layers), 1, sum) > 0)
    
    # deterministic approach: create new recoveries based on inf.time == gamma
    # if(t > gamma) {
    #   newR <- as.integer(rowSums(I[,c((t-gamma):(t-1))]) == gamma)
    # } else {
    #   newR <- R[,t-1]
    # }
    
    # create new recoveries based on Weibull distributed recovery time
    if(r_stochastic == "individual") {
      
      inf_days <- rowSums(I)
      R_prob <- pweibull(inf_days, scale = gamma, shape = 1)
      newR <- rbinom(N, I[,t-1], R_prob)
      
    } else if(r_stochastic == "simulation" & t > rec_time) {
      
      newR <- as.integer(rowSums(as.matrix(I[,c((t-rec_time):(t-1))])) >= rec_time)
      
    } else if(r_stochastic == "simulation" & t <= rec_time) {
      
      newR <- R[,t-1]
    
    } else {stop("r_stochastic must be either 'individual' or 'simulation'")}
    
    # update groups for next time step
    nextS <- S[,t-1] - newI
    nextI <- I[,t-1] + newI - newR
    nextR <- R[,t-1] + newR
    
    # collect old and new observations for each group
    I <- cbind(I, nextI)
    S <- cbind(S, nextS)
    R <- cbind(R, nextR)
  }
  
  res <- list(I = I, S = S, R = R, rec_time = rec_time)
  return(res)
}
```

Test function.

```{r}
sir_res_sim <- model_sir_multiplex(adj_mats = node_tensor, 
                                   tau = c(.3, .1, .2, .3), gamma = 5, r_stochastic = "simulation",
                                   seed_infs = 1, random_seed = 6, t_max = Inf)

{plot(apply(sir_res_sim$S,2,sum), type = "l", xlab = "Time", ylab = "Count")
lines(apply(sir_res_sim$I,2,sum), type = "l", col = "red")
lines(apply(sir_res_sim$R,2,sum), type = "l", col = "blue")
legend(x = 0.5, y = 120, 
       legend = c("Susceptible", "Infected", "Recovered"), 
       lty = 1, bg = "transparent", bty = "n",
       col=c("black", "red", "blue"))}

sir_res_idv <- model_sir_multiplex(adj_mats = node_tensor, 
                                   tau = c(.3, .1, .2, .3), gamma = 5, r_stochastic = "individual",
                                   seed_infs = 1, random_seed = 123, t_max = Inf)

{plot(apply(sir_res_idv$S,2,sum), type = "l", xlab = "Time", ylab = "Count")
lines(apply(sir_res_idv$I,2,sum), type = "l", col = "red")
lines(apply(sir_res_idv$R,2,sum), type = "l", col = "blue")
legend(x = 0.5, y = 120, 
       legend = c("Susceptible", "Infected", "Recovered"), 
       lty = 1, bg = "transparent", bty = "n",
       col=c("black", "red", "blue"))}
```

Run k simulations and collect results in one data frame for plotting.

- Simulation based recovery time

```{r}
sir_res1 <- lapply(1:500, function(x) {
  model_sir_multiplex(adj_mats = node_tensor, 
                      tau = c(.3, .1, .2, .3), gamma = 5, r_stochastic = "simulation",
                      seed_infs = 1, random_seed = NULL, t_max = 100)
  }
)

sir_res_sum1 <- lapply(1:500, function(x) {
  lapply(sir_res1[[x]][1:3], colSums)
  }
)

sir_res_df1 <- lapply(sir_res_sum1, function(x) {
  df <- as.data.frame(do.call("rbind", x)) 
  steps <- ncol(df)
  df %>%
    `colnames<-`(1:steps) %>% 
    rownames_to_column("status") %>% 
    pivot_longer(cols = -1, names_to = "step", values_to = "value") %>% 
    mutate(step = as.integer(step))
  }
)

sir_res_df1 <- lapply(1:500, function(x) {
  sir_res_df1[[x]] %>% 
    mutate(sim_no = x,
           rec_time = sir_res1[[x]][["rec_time"]])
  }
)

sir_res_all1 <- do.call("rbind", sir_res_df1) %>% 
  group_by(status, step) %>% 
  mutate(mean = mean(value),
         sd = sd(value), 
         upper = mean + 2*sd,
         lower = mean - 2*sd) %>% 
  ungroup()

  
```

- Individual based recovery time

```{r}
sir_res2 <- lapply(1:500, function(x) {
  model_sir_multiplex(adj_mats = node_tensor, 
                      tau = c(.3, .1, .2, .3), gamma = 5, r_stochastic = "individual",
                      seed_infs = 1, random_seed = NULL, t_max = Inf)
  }
)

sir_res_sum2 <- lapply(1:500, function(x) {
  lapply(sir_res2[[x]][1:3], colSums)
  }
)

sir_res_df2 <- lapply(sir_res_sum2, function(x) {
  df <- as.data.frame(do.call("rbind", x)) 
  steps <- ncol(df)
  df %>%
    `colnames<-`(1:steps) %>% 
    rownames_to_column("status") %>% 
    pivot_longer(cols = -1, names_to = "step", values_to = "value") %>% 
    mutate(step = as.integer(step))
  }
)

sir_res_df2 <- lapply(1:500, function(x) mutate(sir_res_df2[[x]], sim_no = x))

sir_res_all2 <- do.call("rbind", sir_res_df2) %>% 
  group_by(status, step) %>% 
  mutate(mean = mean(value),
         sd = sd(value), 
         upper = mean + 2*sd,
         lower = mean - 2*sd)

  
```

Plot count of nodes in respective status for each simulation. Compare individual- and simulation-based recovery time.

```{r, fig.width=9}
ggplot(sir_res_all1, aes(x = step, y = value)) +
  geom_line(aes(color = as.factor(status), group = sim_no),
            alpha = .2, linewidth = .5) +
  facet_wrap(~ status) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  theme_light() +
  theme(legend.position = "none")

ggplot(sir_res_all2, aes(x = step, y = value)) +
  geom_line(aes(color = as.factor(status), group = sim_no),
            alpha = .2, linewidth = .5) +
  facet_wrap(~ status) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  theme_light() +
  theme(legend.position = "none")
```

-> When recovery time is sampled once per simulation for all individuals, some epidemics don't end (at least not within 100 days).

-> When recovery time is sampled per individual based on infection duration, some epidemics end very quickly.


Also get compare descriptive statistics.

```{r}
lapply(list(sir_res_all1, sir_res_all2), function(x) {
  x %>% 
  group_by(status) %>% 
  summarise(mean = mean(value),
            min = min(value),
            max = max(value),
            sd = sd(value))
})
```
