---
title: "Exploratory Analyses"
author: "Christine Hedde - von Westernhagen"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(tidyverse)
library(muxViz)
library(ggplot2)
library(igraph)
library(Matrix)
library(rgl)      # output 3d plots
library(tidytext) # ordering factors within facets
library(ggsankey) # sankey diagrams
library(patchwork)
```

# Data prep

```{r}
nodes <- read.csv(here("dummy_data/popnet_nodelist.csv"))
edges <- read.csv(here("dummy_data/popnet_edgelist.csv"))
```

Data checks and wrangling 

```{r}
# types of edges
edges %>% 
  count(edgetype) %>% 
  arrange(desc(n))

# number of nodes
length(unique(c(edges$source, edges$target)))

# missing nodes
nodes[!nodes$node_id %in%  unique(c(edges$source, edges$target)),]

# self-edges
edges %>% 
  filter(source == target)
edges <- filter(edges, !source == target)

# check if all edges are reciprocal
edges %>% 
  mutate(fromto = paste(source, target, sep = "-"),
         tofrom = paste(target, source, sep = "-")) %>% 
  filter(!(fromto %in% tofrom) | !(tofrom %in% fromto)) 

# filter for relations of interest
family <-  c('sibling', 'parent', 'child')

edges <- edges %>% 
  mutate(edgetype = ifelse(edgetype %in% family, "family", edgetype)) %>% 
  filter(edgetype %in% c("family", "work", "household", "school")) %>% 
  arrange(source, target)
```

**Network sampling**

Example code if sampling is necessary.

```{r, eval = FALSE}
child_edges <- edges[edges$edgetype == "child",]

child_nodes <-  child_edges["source"]

keep_relations <- c("child", "parent", "sibling")

# sampling, e.g., 30% of children
sample_frac <- 0.3
pop_size <- nrow(child_nodes)

set.seed(789)
child_sample_idx <- sample(x = 1:pop_size, size = sample_frac * pop_size, replace = FALSE)

child_sample_ids <- child_nodes[child_sample_idx,]

# subset edge data to sampled children in specified relations
egdes_sample <- edges[(edges$source %in% child_sample_ids | edges$target %in% child_sample_ids) &
                        (edges$edgetype %in% keep_relations),]
```

Here, proceed with full data set.

```{r}
# Make multi-layer network
groups <- unique(edges$edgetype)
layers <- length(groups) # (after collapsing family categories etc.)
obs <- nrow(nodes)

node_tensor <- list()
g_list <- list()


for (g in groups) {
  # get first directed graph (otherwise edges are counted twice)
  g_foo <- graph_from_data_frame(edges[edges$edgetype == g, c("source", "target")], 
                                 directed = TRUE,
                                 # include ALL vertices
                                 vertices = nodes$node_id)

  # get adjacency matrix of that graph 
  node_tensor[[g]] <- as_adjacency_matrix(g_foo)

  # now get final undirected graph with multiple edges as edge weights
  g_list[[g]] <- graph_from_adjacency_matrix(node_tensor[[g]],
                                             mode = "undirected", 
                                             weighted = TRUE)
}

# Define layer tensor
layer_tensor <- Matrix(c(0,1,1,1,
                         1,0,1,1,
                         1,1,0,1,
                         1,1,1,0) , nrow = 4, sparse = TRUE)

# Build supra-adjacency matrix
M <- BuildSupraAdjacencyMatrixFromEdgeColoredMatrices(node_tensor, layer_tensor, layers, obs)

# Make single-layer network
#adj_all <- GetAggregateMatrix(node_tensor, layers, obs)
adj_all <- node_tensor[[1]] + node_tensor[[2]] + node_tensor[[3]] + node_tensor[[4]]
g_all <-  graph_from_adjacency_matrix(adj_all, mode = "undirected", weighted = TRUE)
#g_all <- GetAggregateNetworkFromSupraAdjacencyMatrix(M/2, layers, obs)
```

# Explore multi-layer network

## Heatmap

```{r, fig.height=7, fig.width=7}
#rotate <- function(mat) t(mat[nrow(mat):1, ,drop = FALSE])

#M_flip <- rotate(as.matrix(M))

# image(t(M_flip),
#       axes = FALSE)

heatmap(as.matrix(M), Rowv = NA, Colv = NA, useRaster = TRUE,
        col = hcl.colors(100), revC = TRUE,
        labRow = rep(1:nrow(nodes), layers), labCol = rep(1:nrow(nodes), layers))
```

## 3D plot

```{r}
set.seed(789)
lay <- layoutMultiplex(g_list, layout = "comp", box = TRUE)

plot_multiplex3D(g_list,
  layer.layout = lay, layer.colors = c(2:5),
  layer.shift.x = 0.3, layer.space = 2,
  layer.scale = 2.2, #layer.alpha = rep(.2, length(g_list)),
  layer.labels = names(g_list), layer.labels.cex = 1,
  node.size.values = 6,
  FOV = 0
)

snapshot3d("3dplot_dummy.png", fmt = "png", width = 1024, height = 1024)

knitr::include_graphics("3dplot_dummy.png")
```

# Explore multi vs. single-layer centralities

## Compute centralities

```{r}
#deg_single <- degree(g_all, mode = "all")
#deg_single <- (Matrix::t(sumR(adj_all, 1))+sumR(adj_all, 2))/2
deg_single <- strength(g_all)
deg_mult <- c(GetMultiDegree(M, layers, obs, isDirected = FALSE))

eig_single <- eigen_centrality(g_all)$vector
eig_mult <- c(GetMultiEigenvectorCentrality(M, layers, obs))

pr_single <- page_rank(g_all)$vector
pr_mult <- c(GetMultiPageRankCentrality(M, layers, obs))

clo_single <- closeness(g_all)
clo_mult <- GetMultiClosenessCentrality(M, layers, obs)[[1]]
```

## Compare node ranking

```{r, fig.width=4, fig.height=5, warning=FALSE}
plot_centrality_ranking <- function(type, single, multi, node_ids, yaxis_title = TRUE) {
  
  df <- data.frame("single" = single, "multi" = multi) %>% 
    mutate(id = as.factor(node_ids)) %>% 
    pivot_longer(cols = -id, names_to = "layers", values_to = type) %>% 
    group_by(layers) %>% 
    mutate(rank = rank(desc(.data[[type]]), ties.method = "min")) %>% 
    ungroup()
  
  top20_dat <- df %>% 
    arrange(layers, rank) %>% 
    group_by(layers) %>% 
    mutate(top20 = ifelse(row_number() %in% c(1:20), as.character(id), NA)) %>% 
    ungroup() %>% 
    mutate(top20 = ifelse(id %in% top20, TRUE, NA)) %>% 
    filter(top20 == TRUE) %>% 
    select(-.data[[type]]) %>% 
    pivot_wider(values_from = c("rank"), names_from = layers)

  sankey_dat <- top20_dat %>% 
    make_long("single", "multi")
  
  ggplot(sankey_dat, aes(x = x, next_x = next_x, node = node, next_node = next_node,
                         fill = node/max(df$rank)*100, label = node)) +
    geom_sankey(flow.alpha = .6, space = 1.5, width = 0.15) +
    geom_sankey_label(size = 2.2, color = "black", fill = "white", space = 1.5, alpha = 0.8) +
    theme_sankey() +
    scale_fill_viridis_c(option = "plasma") +
    scale_x_discrete(labels = c("single" = "Single-layer", "multi" = "Multi-layer")) +
    labs(x = NULL, fill = "Node rank (%)", title = type) +
    list(if(yaxis_title){labs(y =  "Node rank (absolute)")} else {labs(y = NULL)}) +
    coord_cartesian(xlim = c(1.4, 2)) +
    guides(fill = guide_colorbar(title.hjust = 0.5)) +
    theme(legend.position = c(.87, .5),
          plot.title = element_text(hjust = 0.34, margin = margin(b = -10)))
}

# Degree
plt_deg <- plot_centrality_ranking("Degree centrality", deg_single, deg_mult, nodes$node_id)

# Eigenvector
plt_eig <- plot_centrality_ranking("Eigenvector centrality", eig_single, eig_mult, nodes$node_id, yaxis_title = FALSE)

# PageRank
plt_pr <- plot_centrality_ranking("PageRank centrality", pr_single, pr_mult, nodes$node_id, yaxis_title = TRUE)

# Closeness
plt_clo <- plot_centrality_ranking("Closeness centrality", clo_single, clo_mult, nodes$node_id, yaxis_title = FALSE)
```


```{r, fig.width=8, fig.height=10, warning=FALSE}
(plt_deg + plt_eig) /
  (plt_pr + plt_clo)

ggsave(here("analyses/sankeyplot_all.png"), dpi = 600,
       width = 8.2, height = 10)
```

```{r, fig.width=12, fig.height=5, warning=FALSE}
plt_pr <- plot_centrality_ranking("PageRank centrality", pr_single, pr_mult, nodes$node_id, yaxis_title = FALSE)

(plt_deg + plt_eig + plt_pr)

ggsave(here("analyses/sankeyplot_deg-eig-pr.png"), dpi = 600,
       width = 12.2, height = 5)
```

```{r, fig.width=8, fig.height=5, warning=FALSE}
plt_eig <- plot_centrality_ranking("Eigenvector centrality", eig_single, eig_mult, nodes$node_id)
plt_pr <- plot_centrality_ranking("PageRank centrality", pr_single, pr_mult, nodes$node_id, yaxis_title = FALSE)

plt_eig + plt_pr

ggsave(here("analyses/sankeyplot_eig-pr.png"), dpi = 600,
       width = 8.2, height = 5)
```


# Epidemic modeling

**Function for SIR network model**

Similar to [`epimdr::NetworkSIR()`](https://github.com/objornstad/epimdr/blob/master/rcode/chapter12code.r), [Book link](https://link.springer.com/chapter/10.1007/978-3-319-97487-3_12).

```{r}
model_sir_multiplex <- function(adj_mats, tau, gamma, step_size = 7,
                                seed_infs = 1, random_seed = 789, t_max = Inf,
                                out = "all") {
  #adj_mats = list of separate adj. mats. per layer (= node tensor)
  #tau  =  vector of probabilities of infection across an edge in each layer
  #step_size = length (days) of one iteration 
  #gamma  =  recovery time (not layer specific)
  #seed_infs = no. of infected seed nodes
  #random_seed = seed for sampling seed nodes (lol)
  #t_max = max. no. of time steps
  #out = return value: sir_mat, time_to_inf, all (=both)
  
  layers <- length(adj_mats)
  N <- dim(adj_mats[[1]])[1]
  S <- matrix(rep(1, N), nrow = N, ncol = 1) #First susceptibles (all)
  I <- matrix(rep(0, N), nrow = N, ncol = 1) #First infecteds 
  R <- matrix(rep(0, N), nrow = N, ncol = 1) #First removed 
  
  # sample seed infection(s)
  if(!is.null(random_seed)) set.seed(random_seed)
  
  I1 <- sample(1:N, size = seed_infs)
  # change status of seed nodes
  S[I1,1] <- 0
  I[I1,1] <- 1
  
  # set weekly recovery probability based on Weibull distribution and step size
  #rec_prob <- pweibull(step_size, scale = gamma, shape = 1)
  
  # sample recovery time for every person
  rec_time <- rweibull(N, shape = gamma, scale = 1)
  
  
  # storage for new infections per layer
  newI_layers <- vector(mode = "list", length = layers)
  
  # while there are still infecteds (=not recovered) & t is smaller than t_max...
  t <- 1
  while(sum(I[,t]) > 0 & t <= t_max) {
    
    t <- t + 1
    
    for(l in 1:layers) {
      # vector of infection status neighbors
      infneigh <- adj_mats[[l]] %*% I[,t-1]
      # prob. of infection along each edge (Reed-Frost model)
      pinf <- as.vector(1 - (1 - tau[l])^infneigh)
    
      # create new infections based on pinf in layer
      newI_layers[[l]] <- rbinom(N, S[,t-1], pinf)
    }
    
    # get union of infections across layers
    # -> if infected in one layer, you're infected in all layers
    newI <- as.integer(apply(do.call("cbind", newI_layers), 1, sum) > 0)
    
    # deterministic approach: create new recoveries based on inf.time == gamma
    # if(t > gamma) {
    #   newR <- as.integer(rowSums(I[,c((t-gamma):(t-1))]) == gamma)
    # } else {
    #   newR <- R[,t-1]
    # }
    
    # create new recoveries using cumulative recovery probability
    #newR <- rbinom(N, I[,t-1], rec_prob)
    
    # create new recoveries
    inf_days <- rowSums(I) * step_size
    newR <- as.integer((inf_days - rec_time > 0) & (I[,t-1] == 1)) 

    # update groups for next time step
    nextS <- S[,t-1] - newI
    nextI <- I[,t-1] + newI - newR
    nextR <- R[,t-1] + newR
    
    # collect old and new observations for each group
    I <- cbind(I, nextI)
    S <- cbind(S, nextS)
    R <- cbind(R, nextR)
  }
  
  SIR <- list(S = S, I = I, R = R)
  
  s_times <- rowSums(S)
  s_times[s_times == ncol(S)] <- Inf
      
  switch(out,
         
    sir_mat = return(SIR),
    
    time_to_inf = return(s_times),
    
    all = return(list("sir_mat" = SIR, "time_to_inf" = s_times))
    )
  
}
```

Test function.

```{r}
sir_res_tst <- model_sir_multiplex(adj_mats = node_tensor, 
                                   tau = c(.15, .2, .05, .1), gamma = 5,
                                   seed_infs = 1, random_seed = 7, t_max = Inf,
                                   out = "sir_mat")

{plot(apply(sir_res_tst$S,2,sum), type = "l", xlab = "Time", ylab = "Count", 
      ylim = c(0,128), xlim = c(0,13))
lines(apply(sir_res_tst$I,2,sum), type = "l", col = "red")
lines(apply(sir_res_tst$R,2,sum), type = "l", col = "blue")
legend(x = 0.5, y = 120, 
       legend = c("Susceptible", "Infected", "Recovered"), 
       lty = 1, bg = "transparent", bty = "n",
       col=c("black", "red", "blue"))}

mean(rowSums(sir_res_tst[["I"]]))
sd(rowSums(sir_res_tst[["I"]]))
```

Run k simulations and collect results in one data frame for plotting.

```{r}
# one list per sim. containing status of each node across time steps
sir_res <- lapply(1:1000, function(x) {
  model_sir_multiplex(adj_mats = node_tensor, step_size = 7, 
                      tau = c(.15, .2, .05, .1), gamma = 5,
                      seed_infs = 1, random_seed = x, t_max = Inf,
                      out = "sir_mat")
  }
) 

# cumulative results
sir_res_sum <- lapply(1:1000, function(x) {
  lapply(sir_res[[x]], colSums)
  }
)

# get each simulation run into shape for plotting
sir_res_df <- lapply(sir_res_sum, function(x) {
  df <- as.data.frame(do.call("rbind", x)) 
  steps <- ncol(df)
  df %>%
    `colnames<-`(1:steps) %>% 
    rownames_to_column("status") %>% 
    pivot_longer(cols = -1, names_to = "step", values_to = "value") %>% 
    mutate(step = as.integer(step))
  }
)

sir_res_df <- lapply(1:1000, function(x) mutate(sir_res_df[[x]], sim_no = x))

# bind all simulations into one data frame
sir_res_all <- do.call("rbind", sir_res_df) %>% 
  group_by(status, step) %>% 
  mutate(mean = mean(value),
         sd = sd(value), 
         upper = mean + 2*sd,
         lower = mean - 2*sd)
```

Plot count of nodes in respective status for each simulation.

```{r, fig.width=9}
sir_res_all %>% 
  mutate(status = factor(status, levels = c("S", "I", "R"))) %>% 
  ggplot(aes(x = step, y = value)) +
  geom_line(aes(color = status, group = sim_no),
            alpha = .2, linewidth = .5) +
  facet_wrap(~ status) +
  scale_color_brewer(type = "qual", palette = "Dark2") +
  theme_light() +
  theme(legend.position = "none")
```
```{r, fig.width=9}
sir_res_all %>% 
  mutate(status = factor(status, levels = c("S", "I", "R"))) %>% 
  group_by(sim_no, status) %>% 
  summarise(max = max(value)) %>% 
  ungroup() %>% 
  filter(status == "R") %>% 
  ggplot(aes(x = max, fill = status)) +
  geom_histogram(bins = 100) +
  facet_wrap(~ status) +
  theme_light() +
  theme(legend.position = "none")
```
Also get descriptive statistics.

- Sum of S,I,R

```{r}
sir_res_all %>% 
  group_by(status) %>% 
  summarise(mean = mean(value),
            min = min(value),
            max = max(value),
            sd = sd(value))

```

- Duration of epidemic

```{r}
sir_res_all %>% 
  group_by(sim_no) %>% 
  summarize(duration = max(step)) %>% 
  ungroup() %>% 
  summarise(duration_mean = mean(duration),
            duration_min = min(duration),
            duration_max = max(duration),
            duration_sd = sd(duration))
```

Get only time to infection as result.

```{r}
sir_res_itimes <- lapply(1:500, function(x) {
  model_sir_multiplex(adj_mats = node_tensor, 
                      tau = c(.3, .1, .2, .3), gamma = 5,
                      seed_infs = 1, random_seed = x, t_max = Inf,
                      out = "time_to_inf")
  }
) 

# make data frame
itimes_df <- do.call("cbind", sir_res_itimes) %>% 
  as.data.frame() %>% 
  `colnames<-` (1:length(sir_res_itimes)) %>% 
  mutate(node_id = row_number()) %>% 
  pivot_longer(-node_id, values_to = "time_to_inf", names_to = "sim")
```



